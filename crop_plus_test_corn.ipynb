{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.ncdc.noaa.gov/cdo-web/api/v2/{}/{}'\n",
    "import requests\n",
    "headers = {\n",
    "    'Accept': 'application/json',\n",
    "    'token': 'ItZCKLAcQgyDWSAapgKlybUZGZbqGVNx'\n",
    "}\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = requests.get(url.format('datasets', '?limit=1000'), headers = headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "datasets = pd.DataFrame(datasets.json()['results'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datacoverage</th>\n",
       "      <th>id</th>\n",
       "      <th>maxdate</th>\n",
       "      <th>mindate</th>\n",
       "      <th>name</th>\n",
       "      <th>uid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.00</td>\n",
       "      <td>GHCND</td>\n",
       "      <td>2019-05-08</td>\n",
       "      <td>1763-01-01</td>\n",
       "      <td>Daily Summaries</td>\n",
       "      <td>gov.noaa.ncdc:C00861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.00</td>\n",
       "      <td>GSOM</td>\n",
       "      <td>2019-04-01</td>\n",
       "      <td>1763-01-01</td>\n",
       "      <td>Global Summary of the Month</td>\n",
       "      <td>gov.noaa.ncdc:C00946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.00</td>\n",
       "      <td>GSOY</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>1763-01-01</td>\n",
       "      <td>Global Summary of the Year</td>\n",
       "      <td>gov.noaa.ncdc:C00947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.95</td>\n",
       "      <td>NEXRAD2</td>\n",
       "      <td>2019-05-09</td>\n",
       "      <td>1991-06-05</td>\n",
       "      <td>Weather Radar (Level II)</td>\n",
       "      <td>gov.noaa.ncdc:C00345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.95</td>\n",
       "      <td>NEXRAD3</td>\n",
       "      <td>2019-05-07</td>\n",
       "      <td>1994-05-20</td>\n",
       "      <td>Weather Radar (Level III)</td>\n",
       "      <td>gov.noaa.ncdc:C00708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.00</td>\n",
       "      <td>NORMAL_ANN</td>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>Normals Annual/Seasonal</td>\n",
       "      <td>gov.noaa.ncdc:C00821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.00</td>\n",
       "      <td>NORMAL_DLY</td>\n",
       "      <td>2010-12-31</td>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>Normals Daily</td>\n",
       "      <td>gov.noaa.ncdc:C00823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.00</td>\n",
       "      <td>NORMAL_HLY</td>\n",
       "      <td>2010-12-31</td>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>Normals Hourly</td>\n",
       "      <td>gov.noaa.ncdc:C00824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.00</td>\n",
       "      <td>NORMAL_MLY</td>\n",
       "      <td>2010-12-01</td>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>Normals Monthly</td>\n",
       "      <td>gov.noaa.ncdc:C00822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.25</td>\n",
       "      <td>PRECIP_15</td>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>1970-05-12</td>\n",
       "      <td>Precipitation 15 Minute</td>\n",
       "      <td>gov.noaa.ncdc:C00505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.00</td>\n",
       "      <td>PRECIP_HLY</td>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>1900-01-01</td>\n",
       "      <td>Precipitation Hourly</td>\n",
       "      <td>gov.noaa.ncdc:C00313</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    datacoverage          id     maxdate     mindate  \\\n",
       "0           1.00       GHCND  2019-05-08  1763-01-01   \n",
       "1           1.00        GSOM  2019-04-01  1763-01-01   \n",
       "2           1.00        GSOY  2018-01-01  1763-01-01   \n",
       "3           0.95     NEXRAD2  2019-05-09  1991-06-05   \n",
       "4           0.95     NEXRAD3  2019-05-07  1994-05-20   \n",
       "5           1.00  NORMAL_ANN  2010-01-01  2010-01-01   \n",
       "6           1.00  NORMAL_DLY  2010-12-31  2010-01-01   \n",
       "7           1.00  NORMAL_HLY  2010-12-31  2010-01-01   \n",
       "8           1.00  NORMAL_MLY  2010-12-01  2010-01-01   \n",
       "9           0.25   PRECIP_15  2014-01-01  1970-05-12   \n",
       "10          1.00  PRECIP_HLY  2014-01-01  1900-01-01   \n",
       "\n",
       "                           name                   uid  \n",
       "0               Daily Summaries  gov.noaa.ncdc:C00861  \n",
       "1   Global Summary of the Month  gov.noaa.ncdc:C00946  \n",
       "2    Global Summary of the Year  gov.noaa.ncdc:C00947  \n",
       "3      Weather Radar (Level II)  gov.noaa.ncdc:C00345  \n",
       "4     Weather Radar (Level III)  gov.noaa.ncdc:C00708  \n",
       "5       Normals Annual/Seasonal  gov.noaa.ncdc:C00821  \n",
       "6                 Normals Daily  gov.noaa.ncdc:C00823  \n",
       "7                Normals Hourly  gov.noaa.ncdc:C00824  \n",
       "8               Normals Monthly  gov.noaa.ncdc:C00822  \n",
       "9       Precipitation 15 Minute  gov.noaa.ncdc:C00505  \n",
       "10         Precipitation Hourly  gov.noaa.ncdc:C00313  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataCate = requests.get(url.format('datacategories', '?datasetid=GSOM&limit=1000'), headers = headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataCate = pd.DataFrame(dataCate.json()['results'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EVAP</td>\n",
       "      <td>Evaporation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LAND</td>\n",
       "      <td>Land</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PRCP</td>\n",
       "      <td>Precipitation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SKY</td>\n",
       "      <td>Sky cover &amp; clouds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SUN</td>\n",
       "      <td>Sunshine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TEMP</td>\n",
       "      <td>Air Temperature</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>WATER</td>\n",
       "      <td>Water</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>WIND</td>\n",
       "      <td>Wind</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>WXTYPE</td>\n",
       "      <td>Weather Type</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                name\n",
       "0    EVAP         Evaporation\n",
       "1    LAND                Land\n",
       "2    PRCP       Precipitation\n",
       "3     SKY  Sky cover & clouds\n",
       "4     SUN            Sunshine\n",
       "5    TEMP     Air Temperature\n",
       "6   WATER               Water\n",
       "7    WIND                Wind\n",
       "8  WXTYPE        Weather Type"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataCate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataType = requests.get(url.format('datatypes', \\\n",
    "                                   '?datasetid=GSOM&datacategoryid=WIND&limit=1000'), headers = headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataType = pd.DataFrame(dataType.json()['results'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "location_cate = requests.get(url.format('locationcategories', ''), headers = headers)\n",
    "\n",
    "location_cate = pd.DataFrame(location_cate.json()['results'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CITY</td>\n",
       "      <td>City</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CLIM_DIV</td>\n",
       "      <td>Climate Division</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CLIM_REG</td>\n",
       "      <td>Climate Region</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CNTRY</td>\n",
       "      <td>Country</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CNTY</td>\n",
       "      <td>County</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>HYD_ACC</td>\n",
       "      <td>Hydrologic Accounting Unit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>HYD_CAT</td>\n",
       "      <td>Hydrologic Cataloging Unit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HYD_REG</td>\n",
       "      <td>Hydrologic Region</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>HYD_SUB</td>\n",
       "      <td>Hydrologic Subregion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ST</td>\n",
       "      <td>State</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>US_TERR</td>\n",
       "      <td>US Territory</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ZIP</td>\n",
       "      <td>Zip Code</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                        name\n",
       "0       CITY                        City\n",
       "1   CLIM_DIV            Climate Division\n",
       "2   CLIM_REG              Climate Region\n",
       "3      CNTRY                     Country\n",
       "4       CNTY                      County\n",
       "5    HYD_ACC  Hydrologic Accounting Unit\n",
       "6    HYD_CAT  Hydrologic Cataloging Unit\n",
       "7    HYD_REG           Hydrologic Region\n",
       "8    HYD_SUB        Hydrologic Subregion\n",
       "9         ST                       State\n",
       "10   US_TERR                US Territory\n",
       "11       ZIP                    Zip Code"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "location_cate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "location = requests.get(url.format('locations', '?datasetid=GSOM&locationcategoryid=ST&limit=1000'), headers = headers)\n",
    "location = pd.DataFrame(location.json()['results'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datacoverage</th>\n",
       "      <th>id</th>\n",
       "      <th>maxdate</th>\n",
       "      <th>mindate</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1</td>\n",
       "      <td>FIPS:38</td>\n",
       "      <td>2019-04-01</td>\n",
       "      <td>1893-01-01</td>\n",
       "      <td>North Dakota</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>1</td>\n",
       "      <td>FIPS:46</td>\n",
       "      <td>2019-04-01</td>\n",
       "      <td>1893-01-01</td>\n",
       "      <td>South Dakota</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    datacoverage       id     maxdate     mindate          name\n",
       "34             1  FIPS:38  2019-04-01  1893-01-01  North Dakota\n",
       "41             1  FIPS:46  2019-04-01  1893-01-01  South Dakota"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "location.loc[location['name'].str.contains('Dakota')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The necessary dataTypeID:\n",
    "for precipitation:PRCP\n",
    "for sun:TSUN\n",
    "for TEMP: TAVG\n",
    "for wind: AWND\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Western Corn States:\n",
    "Lowa IA  FIPS:19\n",
    "Nebraska NE FIPS:31\n",
    "Minnesota    MN FIPS:27\n",
    "Kansas    KS FIPS:20\n",
    "South Dakota    SD FIPS:46\n",
    "North Dakota    ND FIPS:38"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations_prcp = requests.get(url.format('stations', \\\n",
    "                                       '?datasetid=GSOM&locationid={}&datatypeid=PRCP&startdate={}-01-01&enddate={}-12-31&limit=1000'\\\n",
    "                                            .format('FIPS:19', 1999, 2008)), headers = headers)                                             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "location_id = {\n",
    "    'illinois' : 'FIPS:17',\n",
    "    'ohio' : 'FIPS:39',\n",
    "    'indiana' : 'FIPS:18',\n",
    "    'wisconsin' : 'FIPS:55',\n",
    "    'missouri' : 'FIPS:29',\n",
    "    'michigan' : 'FIPS:26',\n",
    "    'oklahoma' : 'FIPS:40',\n",
    "    'texas' : 'FIPS:48',\n",
    "    'north carolina' : 'FIPS:37',\n",
    "    'iowa' : 'FIPS:19',\n",
    "    'nebraska' : 'FIPS:31',\n",
    "    'minnesota' : 'FIPS:27',\n",
    "    'kansas' : 'FIPS:20',\n",
    "    'south dakota' : 'FIPS:46',\n",
    "    'north dakota' : 'FIPS:38' \n",
    "}\n",
    "def data_generator(sty, edy, state):\n",
    "    #The prcp data\n",
    "    stations_prcp = requests.get(url.format('stations', \\\n",
    "                                       '?datasetid=GSOM&locationid={}&datatypeid=PRCP&startdate={}-01-01&enddate={}-12-31&limit=1000'\\\n",
    "                                            .format(location_id[state], sty, edy)), headers = headers)\n",
    "\n",
    "    stations_prcp = pd.DataFrame(stations_prcp.json()['results'])\n",
    "\n",
    "    final_res_prcp = pd.DataFrame([])\n",
    "    for item in list(stations_prcp['id']):\n",
    "        item = item[6:]\n",
    "        try:\n",
    "            mytest = pd.read_csv('/Users/yuying/cropPlus/gsom-latest/{}.csv'.format(item))\n",
    "            mytest = mytest[['DATE', 'PRCP']]\n",
    "        except:\n",
    "            print('{} skip one station {}'.format(state, item))\n",
    "            continue\n",
    "        final_res_prcp = pd.concat([mytest, final_res_prcp], sort = False)\n",
    "    final_res_prcp['DATE'] = pd.to_datetime(final_res_prcp['DATE'], format = '%Y-%m')\n",
    "    final_res_prcp = final_res_prcp.loc[(final_res_prcp['DATE'] > '{}-12-31'.\\\n",
    "                                         format(sty-1))&(final_res_prcp['DATE'] < '{}-01-01'.format(edy+1))]\n",
    "    final_res_prcp.dropna(inplace = True)\n",
    "    final_res_prcp = final_res_prcp.groupby('DATE').mean()\n",
    "    final_res_prcp.reset_index(drop = True, inplace = True)\n",
    "    #The temp data\n",
    "    stations_TAVG = requests.get(url.format('stations', \\\n",
    "                                       '?datasetid=GSOM&locationid={}&datatypeid=TAVG&startdate={}-01-01&enddate={}-12-31&limit=1000'.\\\n",
    "                                            format(location_id[state], sty, edy)), headers = headers)\n",
    "\n",
    "    stations_TAVG = pd.DataFrame(stations_TAVG.json()['results'])\n",
    "    final_res_tavg = pd.DataFrame([])\n",
    "    for item in list(stations_TAVG['id']):\n",
    "        item = item[6:]\n",
    "        try:\n",
    "            mytest = pd.read_csv('/Users/yuying/cropPlus/gsom-latest/{}.csv'.format(item))\n",
    "            mytest = mytest[['DATE', 'TAVG']]\n",
    "        except:\n",
    "            print('{} skip one station {}'.format(state, item))\n",
    "            continue\n",
    "        final_res_tavg = pd.concat([mytest, final_res_tavg], sort = False)\n",
    "\n",
    "    final_res_tavg = final_res_tavg.loc[(final_res_tavg['DATE'] > '{}-12'.\\\n",
    "                                         format(sty-1))&(final_res_tavg['DATE'] < '{}-01'.format(edy+1))]\n",
    "    final_res_tavg.dropna(inplace = True)\n",
    "    final_res_tavg = final_res_tavg.groupby('DATE').mean()\n",
    "    final_res_tavg.reset_index(drop = True, inplace = True)\n",
    "\n",
    "\n",
    "    #The awnd data\n",
    "    stations_AWND = requests.get(url.format('stations', \\\n",
    "                                       '?datasetid=GSOM&locationid={}&datatypeid=AWND&startdate={}-01-01&enddate={}-12-31&limit=1000'.\\\n",
    "                                           format(location_id[state], sty, edy)), headers = headers)\n",
    "\n",
    "    stations_AWND = pd.DataFrame(stations_AWND.json()['results'])\n",
    "    final_res_awnd = pd.DataFrame([])\n",
    "    for item in list(stations_AWND['id']):\n",
    "        item = item[6:]\n",
    "        try:\n",
    "            mytest = pd.read_csv('/Users/yuying/cropPlus/gsom-latest/{}.csv'.format(item))\n",
    "            mytest = mytest[['DATE', 'AWND']]\n",
    "        except:\n",
    "            print('{} skip one station {}'.format(state, item))\n",
    "            continue\n",
    "        final_res_awnd = pd.concat([mytest, final_res_awnd], sort = False)\n",
    "\n",
    "    final_res_awnd = final_res_awnd.loc[(final_res_awnd['DATE'] > '{}-12'.\\\n",
    "                                        format(sty-1))&(final_res_awnd['DATE'] < '{}-01'.format(edy+1))]\n",
    "    final_res_awnd.dropna(inplace = True)\n",
    "    final_res_awnd = final_res_awnd.groupby('DATE').mean()\n",
    "    final_res_awnd.reset_index(drop = True, inplace = True)\n",
    "    final_res_awnd['AWND'] = final_res_awnd['AWND'].fillna(0)\n",
    "\n",
    "\n",
    "    final_res = pd.concat([final_res_prcp, final_res_tavg, final_res_awnd], axis = 1)\n",
    "\n",
    "    daterange1 = pd.date_range('{}-01'.format(sty), '{}-01'.format(edy+1), freq='M')\n",
    "    daterange1 = list(daterange1.strftime('%Y-%m-%d'))\n",
    "\n",
    "    final_res['DATE'] = daterange1\n",
    "    final_res['DATE'] = final_res['DATE'].apply(str)\n",
    "\n",
    "    final_res_diff = pd.DataFrame([])\n",
    "    for i in range(1, 13, 1):\n",
    "        if i < 10:\n",
    "             i = '0' + str(i)\n",
    "        else:\n",
    "            i = str(i)\n",
    "        temp = final_res.loc[final_res['DATE'].str.contains('-{}-'.format(i))]\n",
    "        temp_slice = temp[['PRCP', 'TAVG', 'AWND']]\n",
    "\n",
    "        temp_res = temp_slice - temp_slice.iloc[0]\n",
    "\n",
    "        temp_res['DATE'] = temp['DATE']\n",
    "\n",
    "        final_res_diff = pd.concat([temp_res, final_res_diff], sort = False)\n",
    "\n",
    "    new_final = pd.DataFrame(list(range(sty, edy+1)), columns = ['DATE'])\n",
    "\n",
    "    for yr in list(range(sty, edy+1)):\n",
    "        for i in range(1, 13, 1):\n",
    "            if i < 10:\n",
    "                 i = '0' + str(i)\n",
    "            else:\n",
    "                i = str(i)\n",
    "            my_temp1 = final_res_diff.loc[final_res_diff['DATE'].str.contains('{}-{}-'.format(yr, i))]['PRCP']\n",
    "            new_final.loc[new_final['DATE'] == yr, 'delta_prcp_{}'.format(i)] = round(float(my_temp1), 2)\n",
    "            my_temp2 = final_res_diff.loc[final_res_diff['DATE'].str.contains('{}-{}-'.format(yr, i))]['TAVG']\n",
    "            new_final.loc[new_final['DATE'] == yr, 'delta_tavg_{}'.format(i)] = round(float(my_temp2), 2)\n",
    "            my_temp3 = final_res_diff.loc[final_res_diff['DATE'].str.contains('{}-{}-'.format(yr, i))]['AWND']\n",
    "            new_final.loc[new_final['DATE'] == yr, 'delta_awnd_{}'.format(i)] = round(float(my_temp3), 2)\n",
    "\n",
    "\n",
    "    corn_yield = pd.read_csv('corn_yield_{}_{}_{}.csv'.format(state, sty, edy))\n",
    "    corn_yield = corn_yield[['Year', 'Value']]\n",
    "\n",
    "    corn_yield.sort_values(by = ['Year'], inplace = True)\n",
    "\n",
    "    corn_yield['Value'] = corn_yield['Value'] - corn_yield['Value'].iloc[0]\n",
    "\n",
    "    new_final = new_final.merge(corn_yield, left_on = 'DATE', right_on = 'Year')\n",
    "\n",
    "    new_final.drop(axis = 1, columns = ['Year'], inplace = True)\n",
    "    new_final.rename(columns = {'Value' : 'delta_yield_corn_{}'.format(state)}, inplace = True)\n",
    "\n",
    "    new_final.to_csv('final_data_combined_yield_{}_{}_{}.csv'.format(state, sty, edy), index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = list(location_id.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = pd.read_csv('corn_yield_raw.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for state in states:\n",
    "    temp1 = raw.loc[(raw['State'] == state.upper())&(raw['Year']>2008)]\n",
    "    temp2 = raw.loc[(raw['State'] == state.upper())&(raw['Year']<2009)]\n",
    "    temp2.to_csv('corn_yield_{}_1999_2008.csv'.format(state), index = False)\n",
    "    temp1.to_csv('corn_yield_{}_2009_2018.csv'.format(state), index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "illinois skip one station US1ILDG0004\n",
      "illinois skip one station US1ILKN0030\n",
      "illinois skip one station US1ILLV0007\n",
      "illinois skip one station US1ILWN0002\n",
      "illinois skip one station US1ILBU0005\n",
      "illinois skip one station US1ILCP0064\n",
      "illinois skip one station US1ILCP0121\n",
      "illinois skip one station US1ILDG0004\n",
      "illinois skip one station US1ILDW0008\n",
      "illinois skip one station US1ILEF0029\n",
      "illinois skip one station US1ILHM0003\n",
      "illinois skip one station US1ILJF0010\n",
      "illinois skip one station US1ILJH0001\n",
      "illinois skip one station US1ILKN0030\n",
      "illinois skip one station US1ILLV0007\n",
      "illinois skip one station US1ILME0008\n",
      "illinois skip one station US1ILWL0148\n",
      "illinois skip one station US1ILWL0149\n",
      "ohio skip one station US1OHAL0010\n",
      "ohio skip one station US1OHBL0006\n",
      "ohio skip one station US1OHFF0014\n",
      "ohio skip one station US1OHFR0083\n",
      "ohio skip one station US1OHFR0084\n",
      "ohio skip one station US1OHHM0037\n",
      "ohio skip one station US1OHJF0009\n",
      "ohio skip one station US1OHMK0012\n",
      "ohio skip one station US1OHOT0009\n",
      "ohio skip one station US1OHTS0014\n",
      "ohio skip one station USC00331524\n",
      "ohio skip one station USC00334830\n",
      "ohio skip one station USC00339220\n",
      "ohio skip one station USC00339220\n",
      "indiana skip one station US1INBN0035\n",
      "indiana skip one station US1INHY0007\n",
      "indiana skip one station US1INMR0003\n",
      "indiana skip one station US1INTN0001\n",
      "indiana skip one station US1INBN0035\n",
      "indiana skip one station US1INCK0035\n",
      "indiana skip one station US1INCS0016\n",
      "indiana skip one station US1INHY0007\n",
      "indiana skip one station US1INHY0025\n",
      "indiana skip one station US1INMR0003\n",
      "indiana skip one station US1INMR0157\n",
      "indiana skip one station US1INTN0001\n",
      "indiana skip one station USC00125049\n",
      "wisconsin skip one station US1WIBY0002\n",
      "wisconsin skip one station US1WIAD0010\n",
      "wisconsin skip one station US1WIBY0002\n",
      "wisconsin skip one station US1WICR0004\n",
      "wisconsin skip one station US1WIDA0069\n",
      "wisconsin skip one station US1WIGT0006\n",
      "wisconsin skip one station US1WIMR0003\n",
      "wisconsin skip one station US1WIOC0008\n",
      "wisconsin skip one station US1WIPC0025\n",
      "wisconsin skip one station US1WIRC0020\n",
      "wisconsin skip one station US1WISW0006\n",
      "wisconsin skip one station US1WITY0001\n",
      "wisconsin skip one station US1WIWK0065\n",
      "wisconsin skip one station US1WIWK0071\n",
      "wisconsin skip one station US1WIWP0008\n",
      "wisconsin skip one station US1WIWW0022\n",
      "missouri skip one station US1MOBN0011\n",
      "missouri skip one station US1MOBT0001\n",
      "missouri skip one station US1MOCS0002\n",
      "missouri skip one station US1MOLN0001\n",
      "missouri skip one station US1MOWH0001\n",
      "missouri skip one station US1MOBN0011\n",
      "missouri skip one station US1MOBT0001\n",
      "missouri skip one station US1MOCF0010\n",
      "missouri skip one station US1MOCS0002\n",
      "missouri skip one station US1MOGR0115\n",
      "missouri skip one station US1MOLN0001\n",
      "missouri skip one station US1MOMS0006\n",
      "missouri skip one station US1MOOS0009\n",
      "missouri skip one station US1MOOS0010\n",
      "missouri skip one station US1MOPH0051\n",
      "missouri skip one station US1MOPH0052\n",
      "missouri skip one station US1MOPH0053\n",
      "missouri skip one station US1MOPT0020\n",
      "missouri skip one station US1MOSC0007\n",
      "missouri skip one station US1MOSE0034\n",
      "missouri skip one station US1MOSG0006\n",
      "missouri skip one station US1MOST0004\n",
      "missouri skip one station US1MOTX0043\n",
      "missouri skip one station US1MOTX0044\n",
      "missouri skip one station US1MOTX0045\n",
      "missouri skip one station US1MOWH0001\n",
      "michigan skip one station US1MIDL0001\n",
      "michigan skip one station US1MIKZ0006\n",
      "michigan skip one station US1MIMR0001\n",
      "michigan skip one station US1MIWY0007\n",
      "michigan skip one station US1MICS0010\n",
      "michigan skip one station US1MICT0018\n",
      "michigan skip one station US1MIDL0001\n",
      "michigan skip one station US1MIHG0011\n",
      "michigan skip one station US1MIHG0018\n",
      "michigan skip one station US1MIKZ0006\n",
      "michigan skip one station US1MIMC0004\n",
      "michigan skip one station US1MIMR0001\n",
      "michigan skip one station US1MIOC0003\n",
      "michigan skip one station US1MIOW0049\n",
      "michigan skip one station US1MIWY0007\n",
      "michigan skip one station USC00204105\n",
      "michigan skip one station USC00208245\n",
      "michigan skip one station USC00204105\n",
      "oklahoma skip one station US1OKBC0003\n",
      "oklahoma skip one station US1OKBC0003\n",
      "oklahoma skip one station US1OKBC0006\n",
      "oklahoma skip one station US1OKCM0009\n",
      "oklahoma skip one station US1OKCM0012\n",
      "oklahoma skip one station US1OKCV0135\n",
      "oklahoma skip one station US1OKCV0136\n",
      "oklahoma skip one station US1OKGD0016\n",
      "oklahoma skip one station US1OKOK0087\n",
      "oklahoma skip one station US1OKOK0098\n",
      "oklahoma skip one station US1OKPN0013\n",
      "oklahoma skip one station US1OKPT0018\n",
      "oklahoma skip one station US1OKST0014\n",
      "texas skip one station US1TXTV0001\n",
      "texas skip one station US1TXWM0008\n",
      "texas skip one station US1TXAG0010\n",
      "texas skip one station US1TXBEL072\n",
      "texas skip one station US1TXBEL073\n",
      "texas skip one station US1TXBEL074\n",
      "texas skip one station US1TXBEL076\n",
      "texas skip one station US1TXBND066\n",
      "texas skip one station US1TXBRS031\n",
      "texas skip one station US1TXBST130\n",
      "texas skip one station US1TXBXR383\n",
      "texas skip one station US1TXBXR386\n",
      "texas skip one station US1TXBXR390\n",
      "texas skip one station US1TXBZS109\n",
      "texas skip one station US1TXCLL094\n",
      "texas skip one station US1TXCML198\n",
      "texas skip one station US1TXCMR120\n",
      "texas skip one station US1TXCOO005\n",
      "texas skip one station US1TXDA0091\n",
      "texas skip one station US1TXDN0060\n",
      "texas skip one station US1TXDN0061\n",
      "texas skip one station US1TXDS0005\n",
      "texas skip one station US1TXDS0006\n",
      "texas skip one station US1TXEL0049\n",
      "texas skip one station US1TXEL0050\n",
      "texas skip one station USC00416739\n",
      "north carolina skip one station US1NCAV0001\n",
      "north carolina skip one station US1NCAL0036\n",
      "north carolina skip one station US1NCAV0001\n",
      "north carolina skip one station US1NCAX0009\n",
      "north carolina skip one station US1NCBC0134\n",
      "north carolina skip one station US1NCBC0145\n",
      "north carolina skip one station US1NCBC0148\n",
      "north carolina skip one station US1NCBR0090\n",
      "north carolina skip one station US1NCBT0028\n",
      "north carolina skip one station US1NCCB0026\n",
      "north carolina skip one station US1NCCH0035\n",
      "north carolina skip one station US1NCCH0036\n",
      "north carolina skip one station US1NCCN0015\n",
      "north carolina skip one station US1NCCN0094\n",
      "north carolina skip one station US1NCCN0096\n",
      "north carolina skip one station US1NCCR0129\n",
      "north carolina skip one station US1NCCW0051\n",
      "north carolina skip one station US1NCDH0062\n",
      "north carolina skip one station US1NCDH0064\n",
      "north carolina skip one station US1NCDS0024\n",
      "north carolina skip one station US1NCGL0060\n",
      "north carolina skip one station US1NCHR0042\n",
      "north carolina skip one station US1NCHR0043\n",
      "north carolina skip one station US1NCON0124\n",
      "north carolina skip one station US1NCOR0051\n",
      "north carolina skip one station US1NCPM0028\n",
      "north carolina skip one station USC00316805\n",
      "iowa skip one station US1IAAL0006\n",
      "iowa skip one station US1IAAP0008\n",
      "iowa skip one station US1IAAP0009\n",
      "iowa skip one station US1IAAP0010\n",
      "iowa skip one station US1IAAP0011\n",
      "iowa skip one station US1IADV0005\n",
      "iowa skip one station US1IADV0007\n",
      "iowa skip one station US1IADV0008\n",
      "iowa skip one station US1IADV0009\n",
      "iowa skip one station US1IADV0010\n",
      "iowa skip one station US1IADV0013\n",
      "iowa skip one station US1IADV0014\n",
      "iowa skip one station US1IADV0015\n",
      "iowa skip one station US1IADV0016\n",
      "iowa skip one station US1IAJH0027\n",
      "iowa skip one station US1IALC0007\n",
      "iowa skip one station US1IALS0002\n",
      "iowa skip one station US1IAMH0009\n",
      "iowa skip one station US1IAMH0010\n",
      "iowa skip one station US1IAOS0002\n",
      "iowa skip one station US1IAPK0097\n",
      "iowa skip one station US1IAPK0098\n",
      "iowa skip one station US1IAVB0011\n",
      "iowa skip one station US1IAWY0004\n",
      "iowa skip one station US1IAWY0006\n",
      "iowa skip one station US1IAWY0007\n",
      "iowa skip one station US1IAWY0009\n",
      "iowa skip one station US1IAWY0010\n",
      "iowa skip one station US1IAWY0011\n",
      "nebraska skip one station US10arth001\n",
      "nebraska skip one station US10chey001\n",
      "nebraska skip one station US10furn011\n",
      "nebraska skip one station US10jeff017\n",
      "nebraska skip one station US10rich004\n",
      "nebraska skip one station US10arth001\n",
      "nebraska skip one station US10chey001\n",
      "nebraska skip one station US10furn011\n",
      "nebraska skip one station US10jeff017\n",
      "nebraska skip one station US10rich004\n",
      "nebraska skip one station US10sali027\n",
      "nebraska skip one station US10york005\n",
      "nebraska skip one station US1NECA0004\n",
      "nebraska skip one station US1NECA0005\n",
      "nebraska skip one station US1NEDD0001\n",
      "minnesota skip one station US1MNAA0076\n",
      "minnesota skip one station US1MNDK0104\n",
      "minnesota skip one station US1MNHN0005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minnesota skip one station US1MNHN0213\n",
      "minnesota skip one station US1MNPS0006\n",
      "minnesota skip one station US1MNSL0139\n",
      "minnesota skip one station US1MNSR0032\n",
      "minnesota skip one station US1MNWG0066\n",
      "kansas skip one station US1KSCL0002\n",
      "kansas skip one station US1KSWB0003\n",
      "kansas skip one station US1KSBR0002\n",
      "kansas skip one station US1KSBR0004\n",
      "kansas skip one station US1KSBR0005\n",
      "kansas skip one station US1KSBU0034\n",
      "kansas skip one station US1KSCL0002\n",
      "kansas skip one station US1KSCY0004\n",
      "kansas skip one station US1KSCY0015\n",
      "kansas skip one station US1KSDG0063\n",
      "kansas skip one station US1KSDG0064\n",
      "kansas skip one station US1KSDP0016\n",
      "kansas skip one station US1KSEL0095\n",
      "kansas skip one station US1KSLV0010\n",
      "kansas skip one station US1KSMN0025\n",
      "kansas skip one station US1KSMS0005\n",
      "kansas skip one station US1KSNM0006\n",
      "kansas skip one station US1KSOS0023\n",
      "kansas skip one station US1KSPR0018\n",
      "kansas skip one station US1KSRA0019\n",
      "kansas skip one station US1KSRA0025\n",
      "kansas skip one station US1KSRH0015\n",
      "kansas skip one station US1KSRL0048\n",
      "kansas skip one station US1KSRO0010\n",
      "kansas skip one station US1KSSA0029\n",
      "kansas skip one station US1KSWB0003\n",
      "kansas skip one station US1KSWH0010\n",
      "kansas skip one station USC00140497\n",
      "kansas skip one station USC00140497\n",
      "south dakota skip one station US1SDBD0024\n",
      "south dakota skip one station US1SDFR0035\n",
      "south dakota skip one station US1SDPN0068\n",
      "north dakota skip one station US1NDBH0004\n",
      "north dakota skip one station US1NDBH0004\n",
      "north dakota skip one station US1NDDN0002\n",
      "north dakota skip one station US1NDMT0002\n",
      "north dakota skip one station US1NDRL0007\n"
     ]
    }
   ],
   "source": [
    "for state in states:\n",
    "    data_generator(1999, 2008, state)\n",
    "    data_generator(2009, 2018, state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_1999 = {}\n",
    "all_data_2009 = {}\n",
    "for state in states:\n",
    "    all_data_1999[state] = pd.read_csv('final_data_combined_yield_{}_1999_2008.csv'.format(state))\n",
    "    all_data_2009[state] = pd.read_csv('final_data_combined_yield_{}_2009_2018.csv'.format(state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "corr_1999 = {}\n",
    "corr_2009 = {}\n",
    "for state in states:\n",
    "    corr_1999[state] = all_data_1999[state].iloc[:, 1:].corr()\n",
    "    corr_2009[state] = all_data_2009[state].iloc[:, 1:].corr()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#prcp\n",
    "lowa_prcp_1999_2008 = lowa_1999_2008.filter(like = 'prcp', axis = 1).copy()\n",
    "lowa_prcp_1999_2008['delta_yield_corn_lowa'] = lowa_1999_2008.iloc[:, -1]\n",
    "kansas_prcp_1999_2008 = kansas_1999_2008.filter(like = 'prcp', axis = 1).copy()\n",
    "kansas_prcp_1999_2008['delta_yield_corn_kansas'] = kansas_1999_2008.iloc[:, -1]\n",
    "m_prcp_1999_2008 = minnesota_1999_2008.filter(like = 'prcp', axis = 1).copy()\n",
    "m_prcp_1999_2008['delta_yield_corn_minnesota'] = minnesota_1999_2008.iloc[:, -1]\n",
    "n_prcp_1999_2008 = nebraska_1999_2008.filter(like = 'prcp', axis = 1).copy()\n",
    "n_prcp_1999_2008['delta_yield_corn_nebraska'] = nebraska_1999_2008.iloc[:, -1]\n",
    "nd_prcp_1999_2008 = north_dakota_1999_2008.filter(like = 'prcp', axis = 1).copy()\n",
    "nd_prcp_1999_2008['delta_yield_corn_north dakota'] = north_dakota_1999_2008.iloc[:, -1]\n",
    "sd_prcp_1999_2008 = south_dakota_1999_2008.filter(like = 'prcp', axis = 1).copy()\n",
    "sd_prcp_1999_2008['delta_yield_corn_south dakota'] = south_dakota_1999_2008.iloc[:, -1]\n",
    "#tavg\n",
    "lowa_prcp_1999_2008 = lowa_1999_2008.filter(like = 'tavg', axis = 1).copy()\n",
    "lowa_prcp_1999_2008['delta_yield_corn_lowa'] = lowa_1999_2008.iloc[:, -1]\n",
    "kansas_prcp_1999_2008 = kansas_1999_2008.filter(like = 'tavg', axis = 1).copy()\n",
    "kansas_prcp_1999_2008['delta_yield_corn_kansas'] = kansas_1999_2008.iloc[:, -1]\n",
    "m_prcp_1999_2008 = minnesota_1999_2008.filter(like = 'tavg', axis = 1).copy()\n",
    "m_prcp_1999_2008['delta_yield_corn_minnesota'] = minnesota_1999_2008.iloc[:, -1]\n",
    "n_prcp_1999_2008 = nebraska_1999_2008.filter(like = 'tavg', axis = 1).copy()\n",
    "n_prcp_1999_2008['delta_yield_corn_nebraska'] = nebraska_1999_2008.iloc[:, -1]\n",
    "nd_prcp_1999_2008 = north_dakota_1999_2008.filter(like = 'tavg', axis = 1).copy()\n",
    "nd_prcp_1999_2008['delta_yield_corn_north dakota'] = north_dakota_1999_2008.iloc[:, -1]\n",
    "sd_prcp_1999_2008 = south_dakota_1999_2008.filter(like = 'tavg', axis = 1).copy()\n",
    "sd_prcp_1999_2008['delta_yield_corn_south dakota'] = south_dakota_1999_2008.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objs as go\n",
    "import plotly\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#plot for 1999_2008\n",
    "def plot_1999(states, area):\n",
    "    for fc in ['prcp', 'tavg', 'awnd']:\n",
    "        X_axis = list(corr_1999['iowa'].filter(like = fc, axis = 0).index)\n",
    "        #'lowa', 'kansas', 'minnesota', \n",
    "        data = []\n",
    "        for state in states:\n",
    "            trace = go.Scatter(x = X_axis, y = corr_1999[state]['delta_yield_corn_{}'.format(state)].filter(like = fc)\\\n",
    "                            , name = '{}_1999_2008'.format(state))\n",
    "            data.append(trace)\n",
    "        layout = dict(title = 'corn correlation show for different states', xaxis = dict(title = 'factors'), \\\n",
    "                      yaxis = dict(title = 'correlations between yield change and factors'))\n",
    "        fig = dict(data = data, layout = layout)\n",
    "        if not os.path.exists(os.path.dirname('{}/1999_2008/'.format(area))):\n",
    "                os.makedirs(os.path.dirname('{}/1999_2008/'.format(area)))\n",
    "        plotly.offline.plot(fig, filename = '{}/1999_2008/corn correlation show for {}_1999.html'.format(area, fc),\\\n",
    "                            auto_open = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot for 2009_2018\n",
    "def plot_2009(states, area):\n",
    "    for fc in ['prcp', 'tavg', 'awnd']:\n",
    "        X_axis = list(corr_2009['iowa'].filter(like = fc, axis = 0).index)\n",
    "        data = []\n",
    "        for state in states:\n",
    "            trace = go.Scatter(x = X_axis, y = corr_2009[state]['delta_yield_corn_{}'.format(state)].filter(like = fc)\\\n",
    "                            , name = '{}_2009_2018'.format(state))\n",
    "            data.append(trace)\n",
    "        layout = dict(title = 'corn correlation show for different states', xaxis = dict(title = 'factors'), \\\n",
    "                      yaxis = dict(title = 'correlations between yield change and factors'))\n",
    "        fig = dict(data = data, layout = layout)\n",
    "        if not os.path.exists(os.path.dirname('{}/2009_2018/'.format(area))):\n",
    "            os.makedirs(os.path.dirname('{}/2009_2018/'.format(area)))\n",
    "        plotly.offline.plot(fig, filename = '{}/2009_2018/corn correlation show for {}_2009.html'.format(area, fc),\\\n",
    "                        auto_open = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_1999 = pd.DataFrame([])\n",
    "correlation_2009 = pd.DataFrame([])\n",
    "for state in states:\n",
    "    correlation_1999[state] = corr_1999[state]['delta_yield_corn_{}'.format(state)].iloc[:-1]\n",
    "    correlation_2009[state] = corr_2009[state]['delta_yield_corn_{}'.format(state)].iloc[:-1]\n",
    "correlation_1999.to_csv('corn_correlation_1999.csv', index = False)\n",
    "correlation_2009.to_csv('corn_correlation_2009.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "nw = ['north dakota']\n",
    "w = ['south dakota', 'iowa', 'nebraska', 'kansas']\n",
    "e = ['ohio', 'missouri', 'indiana', 'illinois']\n",
    "sw = ['oklahoma', 'texas']\n",
    "ne = ['michigan', 'minnesota', 'wisconsin']\n",
    "se = ['north carolina']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_1999(w, 'w')\n",
    "plot_2009(w, 'w')\n",
    "plot_1999(nw, 'nw')\n",
    "plot_2009(nw, 'nw')\n",
    "plot_1999(e, 'e')\n",
    "plot_2009(e, 'e')\n",
    "plot_1999(sw, 'sw')\n",
    "plot_2009(sw, 'sw')\n",
    "plot_1999(ne, 'ne')\n",
    "plot_2009(ne, 'ne')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
